# 曲线出现的概率：二维KDE方法图解

Title: 曲线出现的概率：二维KDE方法图解
Date: 2024-7-2
Keywords: KDE, Statistic

---

KDE这个方法好，不仅好在它能够将离散的直方图连续化，还好在它能够对高维数据进行度量。本文尝试用二维KDE度量P300实验中曲线出现的概率，并给出直观的比较结果。

---

## 背景：平均得到的典型P300波形

### 平均得到的典型P300波形

P300是常见的脑电信号，它通常需要进行大量重复实验，通过多个时间序列叠加得到典型波形。

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled.png)

### 二维直方图显示P300波形的概率

这里以二维直方图的形式展示了平均P300波形与大量重复样本之间的叠加关系，蓝色区域代表观测值出现的概率低，红色区域代表观测值出现的概率高。

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%201.png)

## 二维KDE方法度量P300的概率

直方图虽然直观，但它的问题是不可导。因此考虑采用之前介绍过的`KDE`方法进行连续化估计。我将数据看作是一坨采样值的集合

$$
\{Y|y=f(t)\}, t \in (-0.5, 1.0)
$$

每次重复实验都是在时间轴$t$上进行一次对所有$t \in (-0.5, 1.0)$值的采样。

[gaussian_kde — SciPy v1.14.0 Manual](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gaussian_kde.html)

### 对每个时间点估计

首先对每个时间点进行估计，假设每个时间点是彼此独立的，在$t=u$时刻

$$
Y_u \sim y=f(u)
$$

这显然是一维KDE问题，得到结果图如下，其中越亮的区域代表出现观测值的概率越高。这种方法的结果看上去不错，但美中不足的是没有考虑到曲线的时间连续性。

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%202.png)

分析有点啰嗦，是一个循环

```python
# Compute kde for every time points

bw_method = 'scott'

scores = []
for j in tqdm(range(len(times)), 'Computing kde'):
    ts = selected_data[:, j]
    kernel = gaussian_kde(ts, bw_method=bw_method)
    score = kernel(bins_center)
    scores.append(score)
scores = np.array(scores).T
```

### 将时间纳入，做二维估计

接下来进行二维KDE计算，将全部观测值纳入统计

$$
Y \sim y = f(t)
$$

由于加入的时间维度，因此KDE能够对全部时间和值的概率进行估计，即

$$
P(t, f(t))
$$

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%203.png)

分析的核心代码如下

```python
xx, yy = np.meshgrid(times, bins_center)
xy_sample = np.vstack([xx.ravel(), yy.ravel()]).T
xx.shape, xy_sample.shape

expand_times = np.concatenate([times[np.newaxis, :] for _ in range(len(selected_data))])
train_data = np.vstack([expand_times.ravel(), selected_data.ravel()]).T

kernel = gaussian_kde(train_data.T, bw_method=bw_method)
score = kernel(xy_sample.T)
```

### 度量每单条曲线的概率

此时，我们可以将二维KDE结果看作是概率密度，可以用它度量每次实验中曲线出现的概率。这样做的思路也很简单，只需要把曲线“穿过”KDE时的路径记录下来，并沿该路径进行积分即可，得到的`KDE得分`即代表该曲线出现的概率大小。下图左、右分别代表平均曲线和随机取的单次实验曲线的路径及积分值，由于我懒得调整量纲，因此只需要比较两个积分值的相对大小即可，可以看到平均曲线的得分高于单次曲线，代表**平均曲线出现的概率更高**。

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%204.png)

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%205.png)

为也进一步说明这些结果，我将全部实验得到的曲线按KDE得分进行排序（如左图所示）。右图是传统的计算各个曲线与平均曲线的欧氏距离。从结果中可以看到，按KDE得分进行排序可以得到更好的结果，因为“更像”典型P300波形的曲线都被排到前面（上面）去了。

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%206.png)

![Untitled](%E6%9B%B2%E7%BA%BF%E5%87%BA%E7%8E%B0%E7%9A%84%E6%A6%82%E7%8E%87%EF%BC%9A%E4%BA%8C%E7%BB%B4KDE%E6%96%B9%E6%B3%95%E5%9B%BE%E8%A7%A3%20b23914704c0c4bb39e1e8e9a33adb4d0/Untitled%207.png)
